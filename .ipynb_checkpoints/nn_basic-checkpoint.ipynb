{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_sample/train/7'),Path('/storage/data/mnist_sample/train/3')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('/storage/data/mnist_sample/train/3/10.png'),Path('/storage/data/mnist_sample/train/3/10000.png'),Path('/storage/data/mnist_sample/train/3/10011.png'),Path('/storage/data/mnist_sample/train/3/10031.png'),Path('/storage/data/mnist_sample/train/3/10034.png'),Path('/storage/data/mnist_sample/train/3/10042.png'),Path('/storage/data/mnist_sample/train/3/10052.png'),Path('/storage/data/mnist_sample/train/3/1007.png'),Path('/storage/data/mnist_sample/train/3/10074.png'),Path('/storage/data/mnist_sample/train/3/10091.png')...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_threes = (path/'train'/'3').ls().sorted()\n",
    "train_sevens = (path/'train'/'7').ls().sorted()\n",
    "train_threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_threes = (path/'valid'/'3').ls().sorted()\n",
    "valid_sevens = (path/'valid'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FAB0500EE50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(train_threes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stack it up in tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_three_tensors = [tensor(Image.open(o)) for o in train_threes]\n",
    "train_seven_tensors = [tensor(Image.open(o)) for o in train_sevens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stacked_threes = torch.stack(three_tensors).float()/255\n",
    "train_stacked_sevens = torch.stack(seven_tensors).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_three_tensors = [tensor(Image.open(o)) for o in valid_threes]\n",
    "train_seven_tensors = [tensor(Image.open(o)) for o in valid_sevens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stacked_threes = torch.stack(train_three_tensors).float()/255\n",
    "valid_stacked_sevens = torch.stack(train_seven_tensors).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train and validation datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.cat([train_stacked_threes, train_stacked_sevens]).view(-1, 28*28)\n",
    "y_train = tensor([1]*len(train_threes) + [0]*len(train_sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = torch.cat([valid_stacked_threes, valid_stacked_sevens]).view(-1, 28*28)\n",
    "y_valid = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dset = list(zip(x_train, y_train))\n",
    "v_dset = list(zip(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize parameters function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, var=1.0): return (torch.randn(size)*var).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5713], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same weight, bias for each input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic linear function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylinear(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4808],\n",
       "        [22.1544],\n",
       "        [ 9.5814],\n",
       "        ...,\n",
       "        [ 8.0364],\n",
       "        [ 9.0833],\n",
       "        [-0.8914]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "preds = mylinear(x_train)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [False],\n",
       "        [False],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == y_train\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128267407417297"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Does changing a weight by a small amount change the accurracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128267407417297"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0] *= 1.0001\n",
    "preds = mylinear(x_train)\n",
    "((preds>0.0) == y_train).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can't take corrects as our loss fn, we need something that changes with minute changes in a weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where((targets==1), 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading datasets in mini-batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dl = DataLoader(t_dset, batch_size=256, shuffle=False)\n",
    "v_dl = DataLoader(v_dset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some practice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias= init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = x_train[:4]\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.8194],\n",
       "        [ -9.1876],\n",
       "        [ -2.6484],\n",
       "        [-15.1669]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = mylinear(inp)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9486, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, y_train[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad.shape, bias.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0130), tensor([-0.0909]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(inp, y_train[:4], mylinear)\n",
    "weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0195), tensor([-0.1364]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(inp, y_train[:4], mylinear)\n",
    "weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resetting gradients to zero is important s loss.backward adds up the previous gradients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's create epoch traiining func with weight updation in each epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in t_dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad.data*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining epoch accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    return ((preds>0.5) == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in v_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2545"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(mylinear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's train for one more epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.1\n",
    "params = weights, bias\n",
    "train_epoch(mylinear, lr, params)\n",
    "validate_epoch(mylinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203 0.9222 0.9262 0.9271 0.9271 0.9276 0.9291 0.9296 0.9301 0.9315 0.933 0.9335 0.934 0.935 0.935 0.9359 0.9379 0.9398 0.9413 0.9418 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(mylinear, lr, params)\n",
    "    print(validate_epoch(mylinear), end =' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOptim:\n",
    "    def __init__(self, params, lr): self.params, self.lr = list(params), lr\n",
    "        \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "            \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyTorch Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate optimizer object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = MyOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb, yb in t_dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9657 0.9677 0.9691 0.9696 0.9696 0.9696 0.9701 0.9701 0.9711 0.9711 0.9716 0.9726 0.9736 0.974 0.9745 0.9745 0.9745 0.975 0.975 0.975 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing MyOptim class with SGD we write our learning as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9108 0.9245 0.9396 0.9494 0.9535 0.9577 0.9603 0.9603 0.9598 0.9597 0.9613 0.9618 0.9617 0.9617 0.9622 0.9627 0.9637 0.9637 0.9642 0.9641 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), 0.01)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using DataLoders and learner.fit instead of train_model func**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(t_dl, v_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.207152</td>\n",
       "      <td>0.368858</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.118368</td>\n",
       "      <td>0.182836</td>\n",
       "      <td>0.871933</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>0.108197</td>\n",
       "      <td>0.933759</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064897</td>\n",
       "      <td>0.080763</td>\n",
       "      <td>0.954367</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055416</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.962218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049653</td>\n",
       "      <td>0.059428</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045783</td>\n",
       "      <td>0.054211</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.050489</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040774</td>\n",
       "      <td>0.047683</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.045480</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing linear model to a neural net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, my_net, opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.316929</td>\n",
       "      <td>0.404704</td>\n",
       "      <td>0.506379</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.148064</td>\n",
       "      <td>0.226106</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>0.114054</td>\n",
       "      <td>0.916585</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053511</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.942100</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040508</td>\n",
       "      <td>0.060590</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.051192</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030133</td>\n",
       "      <td>0.045250</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.041168</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025928</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.034124</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>0.032649</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>0.031409</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019923</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019446</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.027194</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018623</td>\n",
       "      <td>0.026593</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.026046</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.025088</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017345</td>\n",
       "      <td>0.024666</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.017079</td>\n",
       "      <td>0.024277</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.023582</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016376</td>\n",
       "      <td>0.023272</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.022226</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.021249</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.021086</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98233562707901"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_sample')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using resnet18 instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls2 = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls2, resnet18, pretrained=False,\n",
    "                   loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
